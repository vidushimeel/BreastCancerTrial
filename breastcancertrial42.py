# -*- coding: utf-8 -*-
"""Copy of breastCancerTrial1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZVdou06sPCHVhG9VvihxRTQpvcqJYMCM

**Importing necessary libraries:** 
numpy, pandas, matlotlib, joblib, sklearn
"""

import numpy as np
import pandas as pd

from matplotlib import pyplot as plt

import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix

from joblib import dump, load

cols = ['id', 'diagnosis','radius-mean', 'texture-mean', 'perimeter-mean', 'area-mean', 'smoothness-mean', 'compactness-mean', 'concavity-mean', 'concave-points-mean', 'symmetry-mean', 'fractal-dimension-mean', 'radius-se', 'texture-se', 'perimeter-se', 'area-se', 'smoothness-se', 'compactness-se', 'concavity-se', 'concave-points-se', 'symmetry-se', 'fractal-dimension-se', 'radius-ex', 'texture-ex', 'perimeter-ex', 'area-ex', 'smoothness-ex', 'compactness-ex', 'concavity-ex', 'concave-points-ex', 'symmetry-ex', 'fractal-dimension-ex']
df = pd.read_csv('https://ftp.cs.wisc.edu/math-prog/cpo-dataset/machine-learn/cancer/WDBC/WDBC.dat', names=cols)
df.head()

#importing our cancer dataset
x = df.iloc[:, 2:32]
y = df.iloc[:, 1]

x.head() #what we are training model on

y.head() #what we are trying to predict (vars)

#find missing or null data points 
df.isnull().sum()
df.isna().sum()

#replaces missing values in dataset 
from sklearn.impute import SimpleImputer #from the sklearn.impute, import SimpleImputer class  
imputer = SimpleImputer(missing_values =  np.nan, strategy = 'mean') #var imputer = object of SimpleImputer class 
#SimpleImputer ()
imputer.fit(x) #will look for all the missing values in the age and salary column, exclude String columns 
x = imputer.transform(x)#will replace

#encode the Y, which is categorical 
#convert M/B to 1 and 0 
from sklearn.preprocessing import LabelEncoder 
le = LabelEncoder()
y = le.fit_transform(y) #dont need to cast as num py array bc dependent variabel does not have to be numpy array 
print (y)

#split into training and testing 
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)

#feature scaling 
from sklearn.preprocessing import StandardScaler
sc = StandardScaler() #the formula 
#only apply feature scaling to numerical values, leave dummy variables alone 
x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)

#Using RandomForestClassifier method of ensemble class to use Random Forest Classification algorithm

from sklearn.ensemble import RandomForestClassifier
classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)
classifier.fit(x_train, y_train)

y_pred = classifier.predict(x_test)
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
print (cm)

#89 true pos. 
#1 false pos. 
#1 false neg.
#52 true neg. 
#total tests = 143
#to get accuracy rate, do 141/143 = 98.6%